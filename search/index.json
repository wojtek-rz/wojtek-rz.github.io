[{"content":"When searching the web for explanations of numpy.meshgrid function, I found that most of them are useless. They contain very abstract description copied from the documentation and provide one simple example that doesn\u0026rsquo;t explain anything why it works the way it does. And in many cases they forgot that more than 2 dimensions exist. And what is this indexing='ij' parameter? In this post I will try to explain how meshgrid works and why it is useful.\nIntroduction - How to keep array of points in 2D space? Imagine a problem, that you have to store some function $f(x) = y$ on the Cartesian plane (meaning \u0026ldquo;x-y\u0026rdquo; plane). To keep things simple let\u0026rsquo;s assume the function is $f(x) = x^2$. A person not familiar with numpy or programming, but familiar with discrete functions from the school, would probably write something like this:\nFirst approach:\n1 2 3 4 5 6 7 # \u0026#34;arr\u0026#34; is an array of values arr[0] = 0 arr[1] = 1 arr[2] = 4 arr[3] = 9 arr[4] = 16 #in general: arr[x] = y But this code has various problems. It only works when the \u0026ldquo;x\u0026rdquo; values are non-negative integers. When you have some function that doesn\u0026rsquo;t have discrete values or they don\u0026rsquo;t appear in equal intervals, you can\u0026rsquo;t store it in this way. The natural way to store such a function is to create a new array, that represents the the \u0026ldquo;x\u0026rdquo; values. This way, to store one function (or one set of points on the graph), you need two arrays: one for \u0026ldquo;x\u0026rdquo; values and one for \u0026ldquo;y\u0026rdquo; values.\nBetter approach:\n1 2 x = np.array([0, 1, 2, 3, 4]) y = np.array([0, 1, 4, 9, 16]) In this case, the \u0026ldquo;x\u0026rdquo; array represents simple indexes, but in general it can be any array of values. As a generalization, we will think of this two arrays as a set of points in 2D space. Some confusion may arise from the fact, that each point has index, so we have like 3 things: index, x value and y value. But the order of the points is actually not as important as it may seem.\nLet\u0026rsquo;s do the plot of this two functions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import numpy as np import matplotlib.pyplot as plt x = np.array([0, 1, 2, 3, 4, 5]) y = np.array([0, 1, 4, 9, 16, 25]) plt.plot(x, y, \u0026#39;ro\u0026#39;) plt.show() # Changing the order of the points... x = np.array([3, 1, 2, 0, 5, 4]) y = np.array([9, 1, 4, 0, 25, 16]) # does it change the plot? plt.plot(x, y, \u0026#39;ro\u0026#39;) plt.show() After changing the order of the points, the plot looks the same.\nNote that the continous functions are also stored that way. If you think about this, it\u0026rsquo;s not possible to store infinite number of points in the computer memory. What we have to do is to store some of them and if they are close enough, we won\u0026rsquo;t see the difference. To store a continous function in the computer memory to use it in some way, we have to create two arrays: one for \u0026ldquo;x\u0026rdquo; values and one for \u0026ldquo;y\u0026rdquo; values. The \u0026ldquo;x\u0026rdquo; values are usually generated by using np.linspace or np.arange function.\nIn general, when we want to store some N-dimensional set of points in numpy, we have to create N arrays.\nMeshgrid - what is it? The meshgrid function is a way to create a grid of points in a many dimensional space. Simmilary to the graphs we generated above, we want to create graphs that will represent a grid of points.\n1 2 3 gx, gy = np.meshgrid(np.arange(6), np.arange(6)) plt.plot(gx, gy, \u0026#39;o\u0026#39;) plt.show() Each point has coordinates (x_1, x_2, x_3, ..., x_N), where x_1 is the coordinate of the first axis, x_2 is the coordinate of the second axis and so on. The grid is created by taking all possible combinations of the points from the input arrays. We can imagine that each input array great a line, and the points are where the lines intersect.\nThe output of the meshgrid function is a list of arrays, where each array represents one dimension.\n1 2 3 4 print(\u0026#34;gx:\u0026#34;) print(gx) print(\u0026#34;gy:\u0026#34;) print(gy) gx: [[0 1 2 3 4 5] [0 1 2 3 4 5] [0 1 2 3 4 5] [0 1 2 3 4 5] [0 1 2 3 4 5] [0 1 2 3 4 5]] gy: [[0 0 0 0 0 0] [1 1 1 1 1 1] [2 2 2 2 2 2] [3 3 3 3 3 3] [4 4 4 4 4 4] [5 5 5 5 5 5]] We have array of values of the first dimension x - gx and array of values of the second dimension y - gy. One point one grid has it\u0026rsquo;s position determined by the coresponding values in each array - see the ilustration below. The point takes it\u0026rsquo;s first dimension value from the gx array and the second dimension value from the gy array.\nIn the introduction I said that each point on the graph has also it\u0026rsquo;s index in the arrays, that is not important (as the order is not important). Here, each point has two indices, because we have two dimension.\nWhy not use 1-dim arrays? When I try to flatten the 2D coords arrays to 1D arrays, I have:\n1 2 3 4 5 6 7 8 9 gx = gx.flatten() gy = gy.flatten() print(\u0026#34;gx:\u0026#34;) print(gx) print(\u0026#34;gy:\u0026#34;) print(gy) plt.plot(gx, gy, \u0026#39;o\u0026#39;) plt.show() gx: [0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5] gy: [0 0 0 0 0 0 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 4 4 5 5 5 5 5 5] We have exacly the same output. The reason for that is simple. I pointed out that the indices are not important, but the values are. The values are the coordinates of the points. So I changed the indices of the points and everything still works. If I would write the meshgrid function by myself, I would probably use 1D arrays, because it\u0026rsquo;s simpler. But the numpy developers decided to use multi-dimensional arrays.\nOne of the answers it is easier to futher use the meshgrid values in our computations, because we can predict what the values are. When we take meshgrid arrays:\n1 2 # x, y are 1D arrays gx, gy = np.meshgrid(x, y) the following property holds (you can check it by yourself on the examples above):\n1 2 gx[i, j] == x[j] gy[i, j] == y[i] In the gx array, the value is determined entirely by the second index, and in the gy array, the value is determined entirely by the first index.\nThis is very useful, because we can easily see what the values are and how they are ordered, but also what are the dimensions of the arrays.\nThe \u0026lsquo;indexing\u0026rsquo; parameter When I read the description of this parameter the first thing I tried was transposing the output arrays. But that gave exacly the same graph as before, so I though to myself: \u0026ldquo;What is the point of this parameter?\u0026rdquo;.\nThe indexing parameter is used to which array should be the first one in the indices of each points.\nIf you looked confused about the previous paragraph, when the first coordinate i in gx[i,j] what the one that corresponded with the second array y then here\u0026rsquo;s the answer. If you have xy cartesian plane, then the x coordinate actualy points to imaginary \u0026ldquo;column\u0026rdquo; of numbers in space, and the y parameter points to the \u0026ldquo;row\u0026rdquo; of numbers. Because the meshgrid function output should be interpreted as a matrix, when input is on the cartesian plane, the first two dimensions are swapped.\nThere are two possible values of the indexing parameter: 'xy' and 'ij'. The default value is 'xy' and was explained above. When you set it to 'ij', you use matrix indexing in the input arrays, so the first array is the first dimension in the grid arrays and the second array is the second dimension. In ij mode, the following property holds:\n1 2 gx[i, j] == x[i] gy[i, j] == y[j] In 90% of the cases you won\u0026rsquo;t need to know the difference. But there is simple example, when it matters. When you are iterating over the grid arrays, you have to know which dimensions are on which position.\n1 2 3 4 5 6 7 x = np.arange(10) y = np.arange(6) gx, gy = np.meshgrid(x, y) for i in range(len(x)): for j in range(len(y)): gx[i,j] = 0 # do something with gx[i,j] gy[i,j] = 0 --------------------------------------------------------------------------- IndexError Traceback (most recent call last) Cell In[35], line 6 4 for i in range(len(x)): 5 for j in range(len(y)): ----\u0026gt; 6 gx[i,j] = 0 # do something with gx[i,j] 7 gy[i,j] = 0 IndexError: index 6 is out of bounds for axis 0 with size 6 The correct code would be:\n1 2 3 4 5 6 7 x = np.arange(10) y = np.arange(6) gx, gy = np.meshgrid(x, y) for i in range(len(y)): for j in range(len(x)): gx[i,j] = 0 # do something with gx[i,j] gy[i,j] = 0 The \u0026lsquo;sparse\u0026rsquo; parameter The \u0026lsquo;sparse\u0026rsquo; parameter is used to return the output arrays as sparse matrices.\n1 2 3 4 5 gx, gy = np.meshgrid(np.arange(6), np.arange(6), sparse=True) print(\u0026#34;gx:\u0026#34;) print(gx) print(\u0026#34;gy:\u0026#34;) print(gy) gx: [[0 1 2 3 4 5]] gy: [[0] [1] [2] [3] [4] [5]] This strange form of the output uses the broadcast mechanism to save memory.\nThe broadcast is a mechanism that allows numpy to perform operations on arrays of different shapes. The dimensions are compatible, when they are equal or one of them is 1. For example, arrays of shape (3, 1, 3) and (1, 4, 1) are compatible and the resulting array will have shape (3, 4, 3). You can think of this as repeating the smaller array along the missing dimensions, so that it matches the shape of the larger array. In our example (3,1,3) is broadcasted to (3,4,3) by repeating the second dimension 4 times, so accesing (i, j, k) is the same as accesing (i, 0, k).\nThe sparse output is a way to save memory, because if we have a function like this: $f(x,y) = x^2 + y^2$\nwe can use broadcast mechanism on the output of the meshgrid function. Output dimensions in the example are gx.shape=(6, 1) and gy.shape=(1, 6). The resulting array will have shape (6, 6) and the value at position (i, j) will be gx[i, 0]**2 + gy[0, j]**2. So to calculate the function values we would do:\n1 2 3 f_values = gx ** 2 + gy ** 2 print(\u0026#34;f_values:\u0026#34;) print(f_values) f_values: [[ 0 1 4 9 16 25] [ 1 2 5 10 17 26] [ 4 5 8 13 20 29] [ 9 10 13 18 25 34] [16 17 20 25 32 41] [25 26 29 34 41 50]] Conclusion It is much easier to understand something when you know why it was created that way. I hope that this post helped you to understand the meshgrid function and why it is useful. If you have any questions or suggestions, please let me know in the comments.\n","date":"2024-10-12T00:00:00Z","permalink":"https://wojtek-rz.github.io/p/numpy-explained-meshgrid-function/","title":"NumPy explained - meshgrid function"},{"content":"When debugging or trying to maximize the performance of a program, it is often useful to look at the assembly code generated by the compiler. There are many tutorials on how to generate assembly code with gcc command, but many times you have to work with a large, existing codebase that is composed of many CMake targets and library. In this article I will compare different methods to read assembly code from C/C++ projects. Typical use cases are:\nWhen you are dealing with functions independent from the rest of the codebase, or with a few files to analize, best universal tool is \u0026ldquo;Compiler Explorer\u0026rdquo;. When you are working with a large project that uses CMake, you can use default targets to see the assembly of cpp files created by CMake. You can modify the flags used to generate that assembly, details in \u0026ldquo;GCC\u0026rdquo; and \u0026ldquo;CMake\u0026rdquo; sections. When you have a compiled object file you can use objdump tool to see the assembly code, see \u0026ldquo;Assembly from object file\u0026rdquo; section. Compiler Explorer Compiler Explorer is a web-based tool that allows you to see assembly code generated by compiler in \u0026ldquo;real time\u0026rdquo; (every change to source code recompiles the assembly). It was created by Matt Godbolt and is available at godbolt.org. It supports many compilers and you can use it to compare the assembly code generated by different compilers. Assembly code is cleaned up and colorized, so it is easier to read. You can also see which lines of the assembly code correspond to which lines of the source code.\nCompiler Explorer can also be run locally. It is open source and available on GitHub. To install it, you need to have Node.js installed. Clone the repository and run make in the root directory. This will install all the necessary dependencies, build the project, find the compilers installed on your system and start the http server. More detailed instructions can be found here.\nBut most of the time you will want see the assembly of an existing project, containing multiple files and libraries. Fortunately, Compiler Explorer supports CMake. When running locally, to load a project you have to:\nFrom the top menu `Add -\u0026gt; Tree (IDE Mode). From the Tree menu Project -\u0026gt; Choose file and select zipped project file. Select CMake checkbox. Choose build type for cmake, that would contain debug information (e.g. -DCMAKE_BUILD_TYPE=Debug). Write name of the target you would like to compile Select Add new -\u0026gt; Compiler and wait for it to compile. The C++ project I currently work with has 160 files, so Godbolt had a tough challenge, but the website successfully handled the challenge of compiling my project. It wasn\u0026rsquo;t the smoothiest experience, but that\u0026rsquo;s understendable. The site was very slow, and the project took 115 seconds to recompile every change (locally it takes 10 seconds, because I can build it with 12 cpu cores). I had to change the timout value, which was 10 seconds by default (github issue here). To do that you have to create a file from the root directory of the project called etc/config/compiler-explorer.local.properties and add the following line: compileTimeoutMs=100000.\nIt was clear that the main use for the project is to work on server, not locally. I could not see the output CMake generated until the compilation was finished and the files I uploaded to the website were not the same as the ones I had on my computer.\nIt\u0026rsquo;s important to note, that there exists a script from the compiler-explorer project called asm-parser, that will clean the assembly code.\nCompiling with GCC Simple answer: use the -S option, which tells the compiler to stop after the assembly phase. The result will be assembly code with .s extension.\n1 g++ -S main.cpp -o main.s Unless you can read AT\u0026amp;T assembly Syntax you will probably want to use the -masm=intel option to get the Intel syntax.\nThere are a few options to make assembly code more readable. The -fverbose-asm option will add commentary from the original source code. It also adds the architecture and system information at the top of the file.\nYou would like to also remove .cfi directives from your assembly, as they are used for exception handling and debugging. To disable them use -fno-asynchronous-unwind-tables, -fno-exceptions options. Also -fno-rtti and -fno-dwarf2-cfi-asm can be useful, as explained here.\n1 g++ -S -fverbose-asm -fno-asynchronous-unwind-tables -fno-dwarf2-cfi-asm -masm=intel main.cpp -o main.s For example the following C++ code:\n1 2 3 4 5 6 7 8 9 int test (int n) { int total = 0; for (int i = 0; i \u0026lt; n; i++) total += i * i; return total; } Will produce the following assembly code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 _Z4testi: endbr64 push rbp # mov rbp, rsp #, mov DWORD PTR -20[rbp], edi # n, n # main.cpp:29: int total = 0; mov DWORD PTR -8[rbp], 0 # total, # main.cpp:31: for (int i = 0; i \u0026lt; n; i++) mov DWORD PTR -4[rbp], 0 # i, # main.cpp:31: for (int i = 0; i \u0026lt; n; i++) jmp .L9 # .L10: # main.cpp:32: total += i * i; mov eax, DWORD PTR -4[rbp] # tmp85, i imul eax, eax # _1, tmp85 # main.cpp:32: total += i * i; add DWORD PTR -8[rbp], eax # total, _1 # main.cpp:31: for (int i = 0; i \u0026lt; n; i++) add DWORD PTR -4[rbp], 1 # i, .L9: # main.cpp:31: for (int i = 0; i \u0026lt; n; i++) mov eax, DWORD PTR -4[rbp] # tmp86, i cmp eax, DWORD PTR -20[rbp] # tmp86, n jl .L10 #, # main.cpp:34: return total; mov eax, DWORD PTR -8[rbp] # _7, total # main.cpp:35: } pop rbp # ret But assembly code won\u0026rsquo;t always be as readable as this. In most useful cases, you will compile your code with optimization enabled, which will make the assembly code harder to read, as the compiler can also change the order of instructions, remove some of them, or inline some functions.\nYou can also try different approach. Instead of creating assembly file with cpp lines as commentary, you could create a source code with compiled assembly pieces. This can be done with (-Wa) option.\n1 2 3 4 5 6 7 8 9 10 11 -a[sub-option...] turn on listings Sub-options [default hls]: c omit false conditionals d omit debugging directives g include general info h include high-level source l include assembly m include macro expansions n omit forms processing s include symbols =FILE list to FILE (must be last sub-option) We pass to assembler options adhl, so we add -Wa,-adhl. The output would not be valid assembly code, but it will be assembly list mixed with source code. You also have to pass g option to GCC, so the assembler can match source code with assembly code. I also added options to remove .cfi directives from previous example.\n1 g++ -g -fno-asynchronous-unwind-tables -fno-dwarf2-cfi-asm -masm=intel -Wa,-dhln main.cpp \u0026gt; main.lst 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 26:main.cpp **** 27:main.cpp **** int test (int n) 28:main.cpp **** { 159 .loc 1 28 1 160 0000 F30F1EFA endbr64 161 0004 55 push rbp 162 .LCFI9: 163 0005 4889E5 mov rbp, rsp 164 .LCFI10: 165 0008 897DEC mov DWORD PTR -20[rbp], edi 29:main.cpp **** int total = 0; 166 .loc 1 29 7 167 000b C745F800 mov DWORD PTR -8[rbp], 0 167 000000 168 .LBB4: 30:main.cpp **** 31:main.cpp **** for (int i = 0; i \u0026lt; n; i++) 169 .loc 1 31 12 170 0012 C745FC00 mov DWORD PTR -4[rbp], 0 170 000000 171 .loc 1 31 3 172 0019 EB0D jmp .L9 173 .L10: 32:main.cpp **** total += i * i; 174 .loc 1 32 16 discriminator 3 175 001b 8B45FC mov eax, DWORD PTR -4[rbp] 176 001e 0FAFC0 imul eax, eax 177 .loc 1 32 11 discriminator 3 178 0021 0145F8 add DWORD PTR -8[rbp], eax 31:main.cpp **** total += i * i; 179 .loc 1 31 3 discriminator 3 180 0024 8345FC01 add DWORD PTR -4[rbp], 1 181 .L9: 31:main.cpp **** total += i * i; 182 .loc 1 31 21 discriminator 1 183 0028 8B45FC mov eax, DWORD PTR -4[rbp] 184 002b 3B45EC cmp eax, DWORD PTR -20[rbp] 185 002e 7CEB jl .L10 186 .LBE4: 33:main.cpp **** 34:main.cpp **** return total; 187 .loc 1 34 10 188 0030 8B45F8 mov eax, DWORD PTR -8[rbp] 35:main.cpp **** } 189 .loc 1 35 1 190 0033 5D pop rbp 191 .LCFI11: 192 0034 C3 ret However we have those .loc directives, which are used for debugging, so in my view the result of this method looks more messy.\nAnother alternative, would be to use save-temps option, which will save all intermediate files (.s for assembly output, .i for preprocessed input file). This can be easily added to compiler options in your build tool. The results are localted in the build directory, inside the subdirectory for the CMake target.\nAssembly from object file Sometime you may want to see the assembly code from object file. You can use objdump tool for that. For example:\n1 objdump -d -M intel main.o \u0026gt; deas.out Where -d,--disassemble option tells objdump to display the assembler code, and -M option tells objdump to use Intel syntax.\nResult:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 00000000000012c9 \u0026lt;_Z4testi\u0026gt;: 12c9:\tf3 0f 1e fa endbr64 12cd:\t55 push rbp 12ce:\t48 89 e5 mov rbp,rsp 12d1:\t89 7d ec mov DWORD PTR [rbp-0x14],edi 12d4:\tc7 45 f8 00 00 00 00 mov DWORD PTR [rbp-0x8],0x0 12db:\tc7 45 fc 00 00 00 00 mov DWORD PTR [rbp-0x4],0x0 12e2:\teb 0d jmp 12f1 \u0026lt;_Z4testi+0x28\u0026gt; 12e4:\t8b 45 fc mov eax,DWORD PTR [rbp-0x4] 12e7:\t0f af c0 imul eax,eax 12ea:\t01 45 f8 add DWORD PTR [rbp-0x8],eax 12ed:\t83 45 fc 01 add DWORD PTR [rbp-0x4],0x1 12f1:\t8b 45 fc mov eax,DWORD PTR [rbp-0x4] 12f4:\t3b 45 ec cmp eax,DWORD PTR [rbp-0x14] 12f7:\t7c eb jl 12e4 \u0026lt;_Z4testi+0x1b\u0026gt; 12f9:\t8b 45 f8 mov eax,DWORD PTR [rbp-0x8] 12fc:\t5d pop rbp 12fd:\tc3 ret We can see (here and in previous examples) that the names of the functions are mangled and not easily readable. However, in objdump you can use -C option to demangle the names.\n1 2 3 4 00000000000012c9 \u0026lt;test(int)\u0026gt;: 12c9:\tf3 0f 1e fa endbr64 12cd:\t55 push rbp ... We can also see the assembly code of only one function with -disassemble=name option.\n1 objdump --disassemble=\u0026#34;test(int)\u0026#34; -C -M intel main.o \u0026gt; deassembled_test.out Note that without -C option, the name of the function would have to be mangled.\nWe can also have source codes comments in our assembly with -S option, but only when the object was compiled with -g option. Another useful option is --no-show-raw-insn which doesn\u0026rsquo;t show raw bytes of machine code, -r which displays relocation entries and -w option which disables line wrapping of long machine code lines. We can shorten -C -S -r to -CSr option.\n1 objdump --disassemble=\u0026#34;test(int)\u0026#34; -CSr --no-show-raw-insn -M intel main.o \u0026gt; deassembled_test_dbg.out 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 0000000000001129 \u0026lt;test(int)\u0026gt;: int test (int n) { 1129:\tendbr64 112d:\tpush rbp 112e:\tmov rbp,rsp 1131:\tmov DWORD PTR [rbp-0x14],edi int total = 0; 1134:\tmov DWORD PTR [rbp-0x8],0x0 for (int i = 0; i \u0026lt; n; i++) 113b:\tmov DWORD PTR [rbp-0x4],0x0 1142:\tjmp 1151 \u0026lt;test(int)+0x28\u0026gt; total += i * i; 1144:\tmov eax,DWORD PTR [rbp-0x4] 1147:\timul eax,eax 114a:\tadd DWORD PTR [rbp-0x8],eax for (int i = 0; i \u0026lt; n; i++) 114d:\tadd DWORD PTR [rbp-0x4],0x1 1151:\tmov eax,DWORD PTR [rbp-0x4] 1154:\tcmp eax,DWORD PTR [rbp-0x14] 1157:\tjl 1144 \u0026lt;test(int)+0x1b\u0026gt; return total; 1159:\tmov eax,DWORD PTR [rbp-0x8] } 115c:\tpop rbp 115d:\tret When using CMake CMake creates targets for each .cpp file. Targets are named the same as the source file, but with different extension. There are targets for:\nassembly code before passed to assembler, with .s extension, preprocessed source code, with .i extension. It is important to note, that when using many CMake subdirectories the targets are created in the binary_dir of the target\u0026rsquo;s CMakeLists.txt and not the base build directory. So if you would like to generate assembly code for a target src/foo/bar/fun.cpp you would run make src/foo/bar/fun.s from the appropriate build directory.\nWe can see that the generated assembly code is not very readable, beacause we have the same problems as with the previous examples. Fortunately, we can modify flags for the target with CMAKE_CXX_CREATE_ASSEMBLY_SOURCE variable, which is not documented but works.\n1 set(CMAKE_CXX_CREATE_ASSEMBLY_SOURCE \u0026#34;\u0026lt;CMAKE_CXX_COMPILER\u0026gt; $(CXX_DEFINES) $(CXX_INCLUDES) ${CMAKE_CXX_FLAGS} -S -fverbose-asm -fno-asynchronous-unwind-tables -fno-exceptions -masm=intel \u0026lt;SOURCE\u0026gt; -o \u0026lt;ASSEMBLY_SOURCE\u0026gt;\u0026#34;) The names are still mangled, but we can demangle them with some auxiliary tool. Besides that, I have encountered strange bug, that add_compile_options command did not add options to the assembly target (maybe because it was redefined later) and as a consequence the assemblies targets were compiled with different flags than the release build we wanted to optimize. Also be careful to run these .s and .i targets without defining CMAKE_CXX_CREATE_ASSEMBLY_SOURCE flags explicitly, as in my case they included both the debug build flags and the release build flags.\nFuther reading:\nhttps://www.systutorials.com/generate-a-mixed-source-and-assembly-listing-using-gcc/ https://stackoverflow.com/questions/69028715/include-external-header-file-for-c-on-compiler-explorer https://stackoverflow.com/questions/38552116/how-to-remove-noise-from-gcc-clang-assembly-output ","date":"2024-09-13T00:00:00Z","permalink":"https://wojtek-rz.github.io/p/dive-into-your-assembly-code/","title":"Dive into your assembly code!"},{"content":"Let\u0026rsquo;s say we have this C++ class with all five constructors:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Foo { private: int x; public: // Default constructor Foo(int x) : x{x} { std::cout \u0026lt;\u0026lt; \u0026#34;An object was created.\\n\u0026#34;; } Foo(const Foo\u0026amp;) { std::cout \u0026lt;\u0026lt; \u0026#34;Copy constructor called.\\n\u0026#34;; } Foo(Foo\u0026amp;\u0026amp;) { std::cout \u0026lt;\u0026lt; \u0026#34;Move constructor called.\\n\u0026#34;; } Foo\u0026amp; operator=(const Foo\u0026amp;) { std::cout \u0026lt;\u0026lt; \u0026#34;Copy assignment operator called.\\n\u0026#34;; return *this; } Foo\u0026amp; operator=(Foo\u0026amp;\u0026amp;) { std::cout \u0026lt;\u0026lt; \u0026#34;Move assignment operator called.\\n\u0026#34;; return *this; } // Destructor ~Foo() { std::cout \u0026lt;\u0026lt; \u0026#34;An object was destroyed.\\n\u0026#34;; } }; Now, let\u0026rsquo;s examine this piece of code:\n1 2 3 4 5 6 7 8 9 Foo createNewFooObject() { Foo foo{5}; return foo; } int main() { auto foo = createNewFooObject(); return 0; } What output will the program produce? How often will the copy constructor be invoked?\nUnfortunately, C++17 doesn\u0026rsquo;t specify it clearly. Possible outputs include:\n1 2 An object was created. An object was destroyed. 1 2 3 An object was created. Copy constructor called. An object was destroyed. 1 2 3 4 An object was created. Copy constructor called. Copy constructor called. An object was destroyed. When I ran this code, the output was the first option. None of the copy constructors were called. So what rule governs this behavior?\nCopy Elision The C++ compiler uses a technique called copy elision. It ensures that if some calls to copy constructors can be avoided, they are. But first, let\u0026rsquo;s understand when a copy constructor is invoked.\nWhen the Copy Constructor is Called The copy constructor is called whenever an object is initialized (by direct-initialization or copy-initialization) from another object of the same type (unless overload resolution selects a better match or the call is elided), which includes. \u0026ndash; cppreference\nWhile direct initialization is straightforward, initializing an object from an explicit set of constructor arguments (e.g., T object(arg1, arg2, ...);), copy-initialization is more nuanced. According to cppreference, there are several scenarios:\nT object = other; - A named variable is declared with an equal sign. f(other) - Passing an argument to a function by value. return other; - Returning from a function that returns by value. throw object; catch (T object) - Throwing or catching an exception by value. In the first code snippet, two copy constructors should be called: the first when returning from a function (3) and the second when declaring a variable with an equal sign (1).\nAre There Guarantees? Since C++17, there’s something called guaranteed copy elision. It states:\nSince C++17, a prvalue is not materialized until needed, and then it is constructed directly into the storage of its final destination. \u0026ndash; cppreference\nIt means, that even when the syntax suggests a copy constructor should be called, but the value that is the source of the copy is a prvalue, the compiler can optimize it away. The result is just a single constructor call in the final destination.\nThe documentation provides two examples of this guarantee:\nWhen initializing an object in a return statement with a prvalue:\n1 return Foo{5}; This optimization was earlier called URVO - \u0026ldquo;unnamed return value optimization\u0026rdquo; and was a common optimization even before C++17, but is now a part of the standard.\nDuring object initialization when the initializer expression is a prvalue:\n1 Foo x = Foo{Foo{Foo{5}}}; Here, the fact that the constructors are chained together doesn\u0026rsquo;t matter. It\u0026rsquo;s worth noting that \u0026ldquo;move\u0026rdquo; assignments are elided, not \u0026ldquo;copy\u0026rdquo;.\nBeyond that, the standard also specifies situations where the compiler may apply copy elision but isn’t obligated to, such as:\nreturn statements with a named operand. This optimization is called NRVO - \u0026ldquo;named return value optimization\u0026rdquo; and example of that was in the first code snippet. As we saw, most compilers implement this optimization, but it’s not mandatory. Object initialization from a temporary. throw expressions with a named operand. Exception handlers. For more details, check cppreference.\nWith the introduction of move semantics in C++11, the compiler can also elide move constructors the same way it does with copy constructors. {:.notice\u0026ndash;info}\nSome strange example The compilers can be easily tricked when it comes to copy elision.\nTake this code for example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void throwFoo() { Foo foo{5}; foo.printX(); throw foo; } int main() { try{ throwFoo(); } catch(Foo foo){ foo.printX(); std::cout \u0026lt;\u0026lt; \u0026#34;Caught an exception\\n\u0026#34;; } return 0; } The result is:\n1 2 3 4 5 6 7 8 9 An object was created. x: 5 A move constructor called. An object was destroyed. A copy constructor called. x: 1600677166 Caught an exception An object was destroyed. An object was destroyed. The code compiled without any warnings or errors. The output is unexpected, as the object is destroyed and then copied. If there are any rules in the C++ that says I can\u0026rsquo;t do that, they are not easy to find. C++ reference only says about the exception throwing:\nLet ex be the conversion result:\nThe exception object is copy-initialized from ex. The exepction object wasn\u0026rsquo;t copy-initialized, but moved-initialized and produced an undifined behavior. If we changed the catch parameter to const Foo\u0026amp; foo, the output would be very simmiliar but the reported x value would be 0. If we would change throw foo; to throw Foo{5};, the move would be elided.\nMaybe the conclusion is to always use throw with a temporary object, not a named one.\nSummary Before C++17, copy elision was an optimization that compilers could apply, but it wasn\u0026rsquo;t guaranteed. It could generate different results depending on the compiler and optimization level (like debug/release mode). It\u0026rsquo;s worth noting that the code that relies on possible optimizations like \u0026ldquo;named return value optimization\u0026rdquo; is not portable and can produce different results on different compilers.\n","date":"2024-09-13T00:00:00Z","permalink":"https://wojtek-rz.github.io/p/one-word-on-copy-constructors/","title":"One Word on Copy Constructors"},{"content":"Have you ever had the feeling that you have written a cool script or program and you want to show it to the world? If so, then what would be the best way to show it to everyone? I always think about two aspects of a good demo. The first one is whether potential user can experience and play with your software. The second one how much effort the potential user has to put in to load and configure your software.\nOne of the best ways to present your software is to embbed it inside web application. That way, there is no downloading the codebase (explicitely) and no configuration for the user. Someone can just enter the website and start toying with your programs - great example is huggingface where we can play with the models from the frontend UI.\nHere I focus on programs with command line interface to communicate with the world. Some time ago I created an interpreter of the programming language of my invention - Emilia Programming Language. It is written in Haskell and uses CLI to communicate with the world. The online demo can be found here - note that it needs a couple of seconds to load (it\u0026rsquo;s one of the downsides of Webassembly\u0026hellip;).\nI want to embed my Haskell interpreter on a website. I could do this by creating backend service on a \u0026ldquo;compute instance\u0026rdquo; in the cloud that would run the Emilia executable, but I would like to avoid that cost, to keep the demo as cheap as possible for me.\nThing about WebAssembly Actually there is a way to do all the computation on the client side. And I don\u0026rsquo;t have to rewrite all interpreter to Javascript to do that. The answer is WebAssembly.\nIt is a low -evel programming code with assebmler-like instruction set designed for near-native performance. Web browsers implement WebAssembly interpreters and compilers, allowing for much faster execution than Javascript. Many programming language compilers and their extensions allow compilation to WebAssembly in addition to compilation to machine code. (Clang, Go, Haskell).\nNote that this is only the concise tutorial of the steps I had to take in my project. If you\u0026rsquo;re not fammilliar with WebAssembly you won\u0026rsquo;t find detailed explanation of all the concepts here.\nCompiling Haskell to WebAssembly The first thing I had to do was to compile haskell into wasm (WebAssembly), which is probably a thing only a handful of developers have done. Fortunately the creators of Haskell compiler (GHC) have created a GHC backend that compiles to wasm. The official tutorial is available here and you can download the project here.\nAfter running the instalation script all the tools should be available inside ~/.ghc-wasm. You should run source ~/.ghc-wasm/env to add the tools and environment variables to PATH. Then instead of ghc, ghc-pkg, hsc2hs you should use their alternative versions wasm32-wasi-ghc, wasm32-wasi-ghc-pkg and wasm32-wasi-hsc2hs. There is also wrapper for cabal that uses wasm backend for compiling and linking the code: wasm32-wasi-cabal.\nMy project was written with cabal building tool, so instead of cabal build emilia-lang-exe I write:\n1 wasm32-wasi-cabal build emilia-lang-exe Make sure that your project uses one thread for execution (rts -N option), otherwise the project won\u0026rsquo;t compile. {:.notice\u0026ndash;warning}\nThen you can find the compiled wasm binary inside by running cabal list-bin exe:emilia-lang-exe, and copy it to our current workplace.\nAs a result we obtained emilia-lang-exe.wasm binary file written in WebAssembly. You can run it with wasm runtime, a separate program, like wasmtime that came with the wasm-ghc and should be in your path.\n1 wasmtime run emilia-lang-exe.wasm --help 1 2 3 4 Usage: emilia-lang-exe \u0026lt;file\u0026gt; emilia-lang-exe --repl emilia-lang-exe If no file is provided, executable will read from stdin. You can also run this file in the browser and this is what we are going to do.\nRunning WebAssembly binary in the browser Moderm browsers come with the wasm interpreter out of the box. But our CLI binary requires one more thing to run, that is IO interface, a way to communicate with the external world. This was build in the wasmtime interpreter that we already used. Along with some other useful things like: file operations, time and random utilities they create a set of functions called a runtime.\nWe need a bridge that would connect external world to our program. The most established one is called Wasmer.\nThe easiest way is to create a node project with bundler, for example with Vite. After creating you have to install wasmer-sdk:\n1 npm install -S @wasmer/sdk Then you can import it inside main javascript (typescript) file, for example index.ts and use it. On the official website there is simple example of how to use Python binary:\n1 2 3 4 5 6 7 8 9 10 11 import { init, Wasmer } from \u0026#34;@wasmer/sdk\u0026#34;; await init(); const pkg = await Wasmer.fromRegistry(\u0026#34;python/python@3.12\u0026#34;); const instance = await pkg.entrypoint.run({ args: [\u0026#34;-c\u0026#34;, \u0026#34;print(\u0026#39;Hello, World!\u0026#39;)\u0026#34;], }); const { code, stdout } = await instance.wait(); console.log(`Python exited with ${code}: ${stdout}`); In our use case we would like to emulate terminal in the browser. The program that would be executed inside it is emilia-lang-exe binary.\nCreating terminal frontend There is altready javascript library that generates component with nice looking UI and handy functions and is calld xterm. To install the npm module:\n1 npm install @xterm/xterm Add to index.html file the following content:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Wasmer Shell\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;module\u0026#34; defer src=\u0026#34;index.ts\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;terminal\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; It will load the index.ts file with our script.\nInside of it we would like to download the binary from url:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import type { Instance } from \u0026#34;@wasmer/sdk\u0026#34;; // This will save in url variable path to static file with the wasm binary import url from \u0026#34;./emilia-lang-exe.wasm?url\u0026#34;; const { init, initializeLogger, runWasix } = await import(\u0026#34;@wasmer/sdk\u0026#34;); await init(); const module = await WebAssembly.compileStreaming(fetch(url)); const instance = await runWasix(module, { program: \u0026#34;emilia-lang-exe\u0026#34;, args: [\u0026#34;--repl\u0026#34;], }); To connect instances input and output to terminal\u0026rsquo;s intput and output we need helper function:\n1 2 3 4 5 6 function connectStreams(instance: Instance, term: Terminal) { const stdin = instance.stdin?.getWriter(); term.onData(bufforDoubleEnter(data =\u0026gt; stdin?.write(encoder.encode(data)), term)); instance.stdout.pipeTo(new WritableStream({ write: chunk =\u0026gt; term.write(chunk) })); instance.stderr.pipeTo(new WritableStream({ write: chunk =\u0026gt; term.write(chunk) })); } Initialization of the terminal addon:\n1 2 3 4 5 6 7 8 9 import \u0026#34;xterm/css/xterm.css\u0026#34;; import { Terminal } from \u0026#39;@xterm/xterm\u0026#39;; import { WebLinksAddon } from \u0026#39;@xterm/addon-web-links\u0026#39;; const term = new Terminal({ cursorBlink: true, convertEol: true }); term.open(document.getElementById(\u0026#34;terminal\u0026#34;)!); term.loadAddon(new WebLinksAddon()); term.writeln(\u0026#34;Starting...\u0026#34;); And to connect the instance to the terminal we our helper function:\n1 connectStreams(instance, term); Problems After we put everything together we see some major problems. After presssing \u0026ldquo;Enter\u0026rdquo; the console is not creating the new line, nor it is sending the line to the interpreter. \u0026ldquo;Backspace\u0026rdquo; also doesn\u0026rsquo;t work.\nAfter some digging it appears that there exists something called line discipline and it\u0026rsquo;s main tasks include:\nFor example, the standard line discipline processes the data it receives from the hardware driver and from applications writing to the device according to the requirements of a terminal on a Unix-like system. On input, it handles special characters such as the interrupt character (typically Control-C) and the erase and kill characters (typically backspace or delete, and Control-U, respectively) and, on output, it replaces all the LF characters with a CR/LF sequence.\nOur problem can be solved by xterm-pty module.\nA PTY, or pseudoterminal, is an intermediate layer between a process and a terminal. It is not just a pipe, but provides several useful functionalities such as input echo, line editing, conversion, etc. PTY is essential for running real-world CUI programs.\nUsually, xterm.js is used with node-pty. Because node-pty is a binding for the PTY functions provided by the operating system, it does not work on a browser. On the other hand, xterm-pty works on a browser because it has an own implementation of simple Linux-like line discipline.\nTo add it to our project we have to install the node module:\n1 npm i xterm-pty Then we add the following lines:\n1 2 3 4 5 6 7 8 9 10 import { openpty } from \u0026#34;xterm-pty\u0026#34;; const { master, slave } = openpty(); term.loadAddon(master); slave.write(\u0026#34;Starting...\\n\u0026#34;); // instance initalization... connectStreams(instance, slave); Hosting After running\n1 npm run build to build the static website, the result can be available here.\nThe wasmer sdk library doesn\u0026rsquo;t work out of the box. It uses javascript\u0026rsquo;s sharedArrayBuffer to communicate between threads and most browsers block this functionality, unless the headers Cross-Origin-Opener-Policy: same-origin and Cross-Origin-Embedder-Policy: require-corp are present. {:.notice\u0026ndash;warning}\nAll in all, it was a complicated trip, but every problem was solved in the end. I certainly learned a lot along the way.\nThanks for reading, Wojtek\n","date":"2024-08-12T00:00:00Z","permalink":"https://wojtek-rz.github.io/p/from-code-to-execution-running-haskell-programs-on-the-web/","title":"From Code to Execution: Running Haskell Programs on the Web"},{"content":"What is Monad Reader in Haskell? Understanding the MonadReader class in Haskell can be challenging. Online tutorials often focus on implementation details rather than its purpose and usefulness. By the end of this post, you\u0026rsquo;ll have a clear understanding of how MonadReader streamlines environment passing in Haskell, making your code cleaner and more maintainable.\nMotivation The term \u0026lsquo;monad reader\u0026rsquo; comes from the idea that all functions read from a common source.\nFor example, suppose you have a global configuration variable that several functions read from. By using a MonadReader, you can avoid passing that configuration as an argument to each function. The result of our monad would be a function takes this global variable as an argument and then passes it to each function within it.\nHere is a simple example. Suppose we are calculating the total cost of a trip to Europe. We visit three countries, each with its own currency: GBP in the UK, EUR in France and CHF in Switzerland.\n1 2 3 4 5 type ExchangeRate = String -\u0026gt; Double exchangeRateToPln :: ExchangeRate exchangeRateToPln \u0026#34;EUR\u0026#34; = 4.3 exchangeRateToPln \u0026#34;GBP\u0026#34; = 4.9 exchangeRateToPln \u0026#34;CHF\u0026#34; = 3.9 We want to pass a dictionary of currency rates to any function that needs them. The functions can have different numbers of arguments, but they have one thing in common - the last argument is of type ExchangeRate. (the implementation is not important here).\n1 2 3 4 5 6 7 8 getSwitzerlandCost :: Int -\u0026gt; Double -\u0026gt; ExchangeRate -\u0026gt; Double getSwitzerlandCost days nightCost rate = fromIntegral days * nightCost * rate \u0026#34;CHF\u0026#34; getUKCost :: Double -\u0026gt; ExchangeRate -\u0026gt; Double getUKCost flightCost rate = 2.0 * flightCost * rate \u0026#34;GBP\u0026#34; getFranceCost :: Double -\u0026gt; Double -\u0026gt; ExchangeRate -\u0026gt; Double getFranceCost distance fuelCost rate = 2.0 * distance * fuelCost * rate \u0026#34;EUR\u0026#34; Calculating the total cost is now straightforward:\n1 2 3 4 5 6 calculateTotalCost :: ExchangeRate -\u0026gt; Double calculateTotalCost exchangeRateToPln = let switzerlandCost = getSwitzerlandCost 7 100.0 exchangeRateToPln ukCost = getUKCost 200.0 exchangeRateToPln franceCost = getFranceCost 1000.0 1.5 exchangeRateToPln in (switzerlandCost + ukCost + franceCost) Maybe we could get rid of the repetitive exchangeRateToPln? That\u0026rsquo;s what Monad Reader does. It hides the last argument of each function call, so that it behaves like an abstract global variable that is passed unchanged to every to any function in our monad. It is often called the config or environment argument. The syntax of our monad is as follows:\n1 2 3 4 5 6 calculateTotalCost :: ExchangeRate -\u0026gt; Double calculateTotalCost = do switzerlandCost \u0026lt;- getSwitzerlandCost 7 100.0 ukCost \u0026lt;- getUKCost 200.0 franceCost \u0026lt;- getFranceCost 1000.0 1.5 return (switzerlandCost + ukCost + franceCost) What if we want to write something like gifts \u0026lt;- 100? The 100 is a value, not a function that takes ExchangeRate as its last argument. We would write gifts \u0026lt;- return 100 and that\u0026rsquo;s the monadic way to do it.\nBelieve it or not, but in the last code example we actually used a MonadReader. The monadic type here is ExchangeRate -\u0026gt; Double, but we can abstract away the implementation details here and write it with the Reader constructor from Control.Monad.Reader library:\n1 2 3 4 5 calculateTotalCost :: ExchangeRate -\u0026gt; Double -- is the same as calculateTotalCost :: Reader ExchangeRate Double -- in general: -- Reader Env(last argument of functions / environment) Value(return value of the monad) What if we want to store Environment value in a \u0026ldquo;variable\u0026rdquo;? That\u0026rsquo;s what identity function does:\n1 2 calculateTotalCost = do exchangeRate \u0026lt;- (\\x -\u0026gt; x) We can also run some function with changed environment. The most popular use case is when writing interpreters, but let\u0026rsquo;s say we want to calculate the cost of our trip if the economic crisis were to hit.\n1 2 3 4 5 6 7 changeToCrisisRates :: ExchangeRate -\u0026gt; ExchangeRate changeToCrisisRates rates currency = 2 * rates currency calculateTotalCostWhenCrisis :: ExchangeRate -\u0026gt; Double calculateTotalCostWhenCrisis = do rates \u0026lt;- id return (calculateTotalCost (changeToWarRates rates)) Here we have a function that changes the environment changeToCrisisRates :: ExchangeRate -\u0026gt; ExchangeRate and we run the calculateTotalCost calculation with the modified environment.\nThese two applications are so common, that they deserve separate functions within the MonadReader class:\n1 2 3 4 5 ask :: Reader Env Env -- monad that returns Env local :: (Env -\u0026gt; Env) -\u0026gt; (Reader Env Val) -\u0026gt; (Reader Env Val) -- Given a function to modify Env and current calculation, -- return calculation that would run with modified Env. Type Env denotes the environment type, which in our example is ExchangeRate.\nAnother useful function is asks which helps with the problem: what if I want to get only part of Env, not the whole Env.\n1 2 3 asks :: (Env -\u0026gt; a) -\u0026gt; Reader Env a -- given Env selector, create calculation that -- runs selector on Env and returns the value Implementation details Let\u0026rsquo;s try to implement this monad. What is a monadic type here? Remember, that left arrow \u0026lt;- notation is a syntax for \u0026gt;\u0026gt;= with lambda expressions:\n1 2 3 4 5 6 7 calculateCost = do value \u0026lt;- getUKCost 200.0 return value -- is equal to calculateCost = do getUKCost 200.0 \u0026gt;\u0026gt;= (\\value -\u0026gt; return value) So getUKCost 200.0 is of type ExchangeRate -\u0026gt; Double which should be our monadic value. More generally, if m is our monad we would like to have:\n1 m a == Env -\u0026gt; a So here, the monad is a function, that takes environment and returns a value. A useful interpetation is that monads are containers for some values. How can a function be a container? Actually, if we have a function `_ -\u0026gt; 10\u0026rsquo; then no matter what we give it as an argument we will get 10. This makes it 100% certain to hold the value 10. How do we chain such monads? We would like to implement bind function with type:\n1 2 (\u0026gt;\u0026gt;=) :: m a -\u0026gt; (a -\u0026gt; m b) (\u0026gt;\u0026gt;=) :: (Env -\u0026gt; a) -\u0026gt; (a -\u0026gt; (Env -\u0026gt; b)) It takes a monadic value with type m a and passed the value a to the function, which returns the monadic value m b. But to get value a from monad Env -\u0026gt; a we have to pass Env. And that\u0026rsquo;s exacly how we implement it:\n1 h \u0026gt;\u0026gt;= f = \\w -\u0026gt; f (h w) w We get the value from h with h w and pass it to f. Because the result of bind must also have monadic value m b == Env -\u0026gt; b, and the result of f is a value inside the function container, we have to pass again w to the result f (h w) to get the value inside the monad.\nAnd even pure arithmetic has an interesting interpretation. It is a calculation that ignores the result and always returns the value.\n1 return a = \\_ -\u0026gt; a In many places you will see such implementation:\n1 2 3 instance Monad ((-\u0026gt;) r) where return x = \\_ -\u0026gt; x h \u0026gt;\u0026gt;= f = \\w -\u0026gt; f (h w) w where the most confusing part is this ((-\u0026gt;) r). This is type constructor which is missing the argument - value it will take. With list monad we have:\n1 2 3 instance Monad [] where xs \u0026gt;\u0026gt;= f = concat $ map f xs return x = [x] and [] is a constructor that is also missing value. For example if we write [] Int, we give the type constructor [] type Int and the result is [Int]. So we can say that [] is of kind * -\u0026gt; *, where * is a type. Even more, (-\u0026gt;) r is also a type constructor of kind * -\u0026gt; *. If we give it the type String we get (-\u0026gt;) r String which can be also written as r -\u0026gt; String. In the Haskell documentation, m = (-\u0026gt;) r, so m is a monad type constructor. Therefore m a expands to r -\u0026gt; a.\nUseful exercises are writing functor and applicative instances for the monad function, as well as ask and local functions (I explained what they do in the previous section). These implementations are:\n1 2 3 4 5 class Monad m =\u0026gt; MonadReader r m | m -\u0026gt; r where ask :: m r -- we now now that m r expands to r -\u0026gt; r, so only id fits ask = id local :: (r -\u0026gt; r) -\u0026gt; m a -\u0026gt; m a local f previousReader env = previousReader (f env) And that is how we can play with MonadReader.\n","date":"2024-03-30T00:00:00Z","permalink":"https://wojtek-rz.github.io/p/global-variables-in-haskell-with-monadreader/","title":"Global variables in Haskell with MonadReader!"}]